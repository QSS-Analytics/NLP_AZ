


## GloVe: Global Vectors for Word Representation by Facebook AI Research!



This repo shows the implementaion of loading the word embeddings into Keras model for Azerbaijani language in R and Python noteboooks.

Note: In Python notebook only Mac and Linux users will be able to clone and run the example because __data.table__ is not available for Windows users.

We will add an additonal method for Windows users, as well but later.

Word embeddings were trained by Facebook Research. 

E. Grave*, P. Bojanowski*, P. Gupta, A. Joulin, T. Mikolov, [Learning Word Vectors for 157 Languages](https://arxiv.org/abs/1802.06893)

```
@inproceedings{grave2018learning,
  title={Learning Word Vectors for 157 Languages},
  author={Grave, Edouard and Bojanowski, Piotr and Gupta, Prakhar and Joulin, Armand and Mikolov, Tomas},
  booktitle={Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}
```
